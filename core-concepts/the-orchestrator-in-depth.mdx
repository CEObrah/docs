---
title: "The Orchestrator: In-Depth"
description: "A deep dive into the runtime Mixture-of-Experts (MoE) engine that powers the MindLab platform."
---

The core of the MindLab platform is the Orchestrator. It is not a single, monolithic AI, but a runtime Mixture-of-Experts (MoE) engine that intelligently coordinates the work of specialized agents to achieve complex business objectives.

## Runtime MoE vs. Training-time MoE

Traditional AI development has focused on "training-time MoE," where massive, sparse models are created. While powerful, these models are rigid and expensive to change.

MindLab's "runtime MoE" is a more agile and adaptable paradigm. Instead of relying on a single, static model, the Orchestrator dynamically routes tasks to a diverse registry of specialized agents. This allows for continuous improvement and adaptation without the need to retrain foundational models.

## The Orchestration Process

The Orchestrator's primary function is to factorize user intent into a series of atomic, testable sub-tasks and then route those tasks to the most appropriate specialist agent.

<Steps>
  <Step title="Factorization">
    The Orchestrator receives a high-level objective and breaks it down into a directed acyclic graph (DAG) of smaller, well-defined sub-tasks.
  </Step>
  <Step title="Routing">
    For each sub-task, the Orchestrator queries the Expert Registry to find the optimal agent. This decision is based on a combination of factors, including skill tags, uncertainty, cost/latency envelopes, and policy gates.
  </Step>
  <Step title="Execution">
    The Orchestrator dispatches the sub-tasks and monitors their execution via the Flow Engine.
  </Step>
</Steps>

<Tip>
A common and powerful topology for this process is a **Planner → Solver → Reviewer → Verifier** chain, where each step has the ability to veto the process or cascade it to an alternative agent, ensuring a high degree of quality and control.
</Tip>