---
title: "15. Risks, Limitations & Ethics"
description: "MindLab is committed to the responsible development and deployment of AI, with a transparent approach to risks, limitations, and ethical considerations."
---

## 15.1 Policy Drift

As MindLab learns from feedback, policies may drift away from the original intent. Continuous monitoring, regression testing and human oversight (HITL) mitigate this risk.

## 15.2 Retrieval Brittleness

Knowledge bases may contain outdated or biased information. Mitigations include curated sources, human review, feedback loops to demote low-quality content and transparent citations.

## 15.3 Evaluation Leakage & Gaming

Agents may inadvertently learn from evaluation tasks or optimize for metrics rather than true quality. Using held-out evaluation sets, randomized sampling, multi-metric evaluation and adversarial review reduces gaming.

## 15.4 Bias & Fairness

Agents trained on biased data may perpetuate inequities. MindLab enforces fairness checks in evaluation metrics, supports counterfactual testing and allows organizations to define fairness policies in the Norms section of CADANCEâ„¢.

## 15.5 Privacy & Consent

Storing long-term memory raises privacy concerns. MindLab requires explicit consent for data storage, allows deletion or anonymization of memories and supports data residency requirements.

## 15.6 Systemic Dependence

Heavy reliance on AI can reduce human expertise. MindLab encourages HITL checkpoints and aims to augment rather than replace humans.